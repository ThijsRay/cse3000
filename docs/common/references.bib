% Encoding: UTF-8

@article{kohn_2018_gender,
  title="{Gender Stereotype Analysis on Reddit using Word Embeddings}",
  author={Kohn, Aaron},
  year=2018,
  month=03
}

@ARTICLE{bolukbasi_2016_quantifying_stereotypes,
       author = {{Bolukbasi}, Tolga and {Chang}, Kai-Wei and {Zou}, James and
         {Saligrama}, Venkatesh and {Kalai}, Adam},
        title = "{Quantifying and Reducing Stereotypes in Word Embeddings}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Statistics - Machine Learning},
         year = 2016,
        month = jun,
          eid = {arXiv:1606.06121},
        pages = {arXiv:1606.06121},
archivePrefix = {arXiv},
       eprint = {1606.06121},
 primaryClass = {cs.CL},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2016arXiv160606121B},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{caliskan_2017_semantics_language_corpora,
title = "Semantics derived automatically from language corpora contain human-like biases",
abstract = "Machine learning is a means to derive artificial intelligence by discovering patterns in existing data. Here, we show that applying machine learning to ordinary human language results in human-like semantic biases. We replicated a spectrum of known biases, as measured by the Implicit Association Test, using a widely used, purely statistical machine-learning model trained on a standard corpus of text from the World Wide Web. Our results indicate that text corpora contain recoverable and accurate imprints of our historic biases, whether morally neutral as toward insects or flowers, problematic as toward race or gender, or even simply veridical, reflecting the status quo distribution of gender with respect to careers or first names. Our methods hold promise for identifying and addressing sources of bias in culture, including technology.",
keywords = "cs.AI, cs.CL, cs.CY, cs.LG",
author = "Aylin Caliskan and Bryson, {Joanna J} and Arvind Narayanan",
year = "2017",
month = "4",
day = "14",
doi = "10.1126/science.aal4230",
language = "English",
volume = "356",
pages = "183--186",
journal = "Science",
issn = "0036-8075",
publisher = "American Association for the Advancement of Science",
number = "6334",

}

@article{nissim_fair_is_better_2020,
author = {Nissim, Malvina and van Noord, Rik and van der Goot, Rob},
title = {Fair is Better than Sensational: Man is to Doctor as Woman is to Doctor},
journal = {Computational Linguistics},
volume = {0},
number = {ja},
pages = {1-17},
year = {2020},
month = {03},
doi = {10.1162/COLI_a_00379},
URL = { https://doi.org/10.1162/COLI_a_00379 },
eprint = { https://doi.org/10.1162/COLI_a_00379 },
abstract = { Analogies such as man is to king as woman is to X are often used to illustrate the amazing power of word embeddings. Concurrently, they have also been used to expose how strongly human biases are encoded in vector spaces trained on natural language, with examples like man is to computer programmer as woman is to homemaker. Recent work has shown that analogies are in fact not an accurate diagnostic for bias, but this does not mean that they are not used anymore, or that their legacy is fading. Instead of focusing on the intrinsic problems of the analogy task as a bias detection tool, we discuss a series of issues involving implementation as well as subjective choices, which might have yielded a distorted picture of bias in word embeddings. We stand by the truth that human biases are present in word embeddings, and of course, to the need to address them. But analogies are not an accurate tool to do so, and the way they have been most often used has exacerbated some possibly non-existing biases and perhaps hid others. Because they are still widely popular, and some of them have become classics within and outside the NLP community, we deem it important to provide a series of clarifications that should put well-known, and potentially new analogies into the right perspective. }
}

@inproceedings{gonen-goldberg-2019-lipstick-pig,
    title = "Lipstick on a Pig: {D}ebiasing Methods Cover up Systematic Gender Biases in Word Embeddings But do not Remove Them",
    author = "Gonen, Hila  and
      Goldberg, Yoav",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N19-1061",
    doi = "10.18653/v1/N19-1061",
    pages = "609--614",
    abstract = "Word embeddings are widely used in NLP for a vast range of tasks. It was shown that word embeddings derived from text corpora reflect gender biases in society. This phenomenon is pervasive and consistent across different word embedding models, causing serious concern. Several recent works tackle this problem, and propose methods for significantly reducing this gender bias in word embeddings, demonstrating convincing results. However, we argue that this removal is superficial. While the bias is indeed substantially reduced according to the provided bias definition, the actual effect is mostly hiding the bias, not removing it. The gender bias information is still reflected in the distances between {``}gender-neutralized{''} words in the debiased embeddings, and can be recovered from them. We present a series of experiments to support this claim, for two debiasing methods. We conclude that existing bias removal techniques are insufficient, and should not be trusted for providing gender-neutral modeling.",
}

@ARTICLE{2017arXiv171108412G,
       author = {{Garg}, Nikhil and {Schiebinger}, Londa and {Jurafsky}, Dan and
         {Zou}, James},
        title = "{Word Embeddings Quantify 100 Years of Gender and Ethnic Stereotypes}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Computation and Language, Computer Science - Computers and Society},
         year = 2017,
        month = nov,
          eid = {arXiv:1711.08412},
        pages = {arXiv:1711.08412},
archivePrefix = {arXiv},
       eprint = {1711.08412},
 primaryClass = {cs.CL},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2017arXiv171108412G},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{2018arXiv180309288K,
       author = {{Kozlowski}, Austin C. and {Taddy}, Matt and {Evans}, James A.},
        title = "{The Geometry of Culture: Analyzing Meaning through Word Embeddings}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Computation and Language},
         year = 2018,
        month = mar,
          eid = {arXiv:1803.09288},
        pages = {arXiv:1803.09288},
archivePrefix = {arXiv},
       eprint = {1803.09288},
 primaryClass = {cs.CL},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2018arXiv180309288K},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@inproceedings{grave2018learning,
  title={Learning Word Vectors for 157 Languages},
  author={Grave, Edouard and Bojanowski, Piotr and Gupta, Prakhar and Joulin, Armand and Mikolov, Tomas},
  booktitle={Proceedings of the International Conference on Language Resources and Evaluation (LREC 2018)},
  year={2018}
}

@INPROCEEDINGS{Levy14linguisticregularities,
    author = {Omer Levy and Yoav Goldberg},
    title = {Linguistic regularities in sparse and explicit word representations},
    booktitle = {In Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL)},
    year = {2014}
}

@ARTICLE{2020arXiv200304036Z,
       author = {{Zhu}, Xunjie and {de Melo}, Gerard},
        title = "{Sentence Analogies: Exploring Linguistic Relationships and Regularities in Sentence Embeddings}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Computation and Language},
         year = 2020,
        month = mar,
          eid = {arXiv:2003.04036},
        pages = {arXiv:2003.04036},
archivePrefix = {arXiv},
       eprint = {2003.04036},
 primaryClass = {cs.CL},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2020arXiv200304036Z},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{li1992random,
  title={Random texts exhibit Zipf's-law-like word frequency distribution},
  author={Li, Wentian},
  journal={IEEE Transactions on information theory},
  volume={38},
  number={6},
  pages={1842--1845},
  year={1992},
  publisher={IEEE}
}


@book{Zipf-1935,
  address    = {Cambridge, Mass.},
  author     = {Zipf, George},
  publisher  = {M.I.T. Press},
  title      = {The Psychobiology of Language: An Introduction to Dynamic Philology},
  year       = {1935},
  iso_code   = {},
  olac_field = {},
  wals_code  = {}
}

@inproceedings{vylomova-etal-2016-take,
    title = "Take and Took, Gaggle and Goose, Book and Read: Evaluating the Utility of Vector Differences for Lexical Relation Learning",
    author = "Vylomova, Ekaterina  and
      Rimell, Laura  and
      Cohn, Trevor  and
      Baldwin, Timothy",
    booktitle = "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2016",
    address = "Berlin, Germany",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P16-1158",
    doi = "10.18653/v1/P16-1158",
    pages = "1671--1682",
}

@inproceedings{10.1145/3219819.3219885,
author = {Grbovic, Mihajlo and Cheng, Haibin},
title = {Real-Time Personalization Using Embeddings for Search Ranking at Airbnb},
year = {2018},
isbn = {9781450355520},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3219819.3219885},
doi = {10.1145/3219819.3219885},
booktitle = {Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
pages = {311–320},
numpages = {10},
keywords = {user modeling, personalization, search ranking},
location = {London, United Kingdom},
series = {KDD ’18}
}

@inproceedings{large-scale-hoang-2017,
author = {Hoang, Phuong and Javed, Faizan and Mahoney, Thomas and McNair, Matt},
year = {2017},
month = {02},
pages = {},
title = {Large-Scale Occupational Skills Normalization for Online Recruitment}
}

@article{dastin_2018,
 author  = {Dastin, Jeffrey},
 date    = {2018-10-10},
 title   = {Amazon scraps secret AI recruiting tool that showed bias against women},
 journal = {Reuters},
 url     = {https://www.reuters.com/article/us-amazon-com-jobs-automation-insight-idUSKCN1MK08G},
}

@inproceedings{10.1145/3306618.3314270,
author = {Swinger, Nathaniel and De-Arteaga, Maria and Heffernan IV, Neil Thomas and Leiserson, Mark DM and Kalai, Adam Tauman},
title = {What Are the Biases in My Word Embedding?},
year = {2019},
isbn = {9781450363242},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3306618.3314270},
doi = {10.1145/3306618.3314270},
booktitle = {Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society},
pages = {305–311},
numpages = {7},
keywords = {bias, fairness, word embeddings},
location = {Honolulu, HI, USA},
series = {AIES ’19}
}

@inproceedings{ethayarajh-etal-2019-understanding,
    title = "Understanding Undesirable Word Embedding Associations",
    author = "Ethayarajh, Kawin  and
      Duvenaud, David  and
      Hirst, Graeme",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P19-1166",
    doi = "10.18653/v1/P19-1166",
    pages = "1696--1705",
    abstract = "Word embeddings are often criticized for capturing undesirable word associations such as gender stereotypes. However, methods for measuring and removing such biases remain poorly understood. We show that for any embedding model that implicitly does matrix factorization, debiasing vectors post hoc using subspace projection (Bolukbasi et al., 2016) is, under certain conditions, equivalent to training on an unbiased corpus. We also prove that WEAT, the most common association test for word embeddings, systematically overestimates bias. Given that the subspace projection method is provably effective, we use it to derive a new measure of association called the relational inner product association (RIPA). Experiments with RIPA reveal that, on average, skipgram with negative sampling (SGNS) does not make most words any more gendered than they are in the training corpus. However, for gender-stereotyped words, SGNS actually amplifies the gender association in the corpus.",
}

@article{word_embedding_zipf_context,
    author = {Gao, Lizheng and Zhou, Gang and Luo, Junyong and Huang, Yongzhong},
    year = {2019},
    month = {11},
    pages = {1-1},
    title = {Word Embedding with Zipf’s Context},
    volume = {PP},
    journal = {IEEE Access},
    doi = {10.1109/ACCESS.2019.2954691}
}

@ARTICLE{2015arXiv150106307W,
       author = {{Wagner}, Claudia and {Garcia}, David and {Jadidi}, Mohsen and
         {Strohmaier}, Markus},
        title = "{It's a Man's Wikipedia? Assessing Gender Inequality in an Online Encyclopedia}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Computers and Society, Computer Science - Social and Information Networks},
         year = 2015,
        month = jan,
          eid = {arXiv:1501.06307},
        pages = {arXiv:1501.06307},
archivePrefix = {arXiv},
       eprint = {1501.06307},
 primaryClass = {cs.CY},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2015arXiv150106307W},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@inproceedings{lauscher-glavas-2019-consistently,
    title = "Are We Consistently Biased? Multidimensional Analysis of Biases in Distributional Word Vectors",
    author = "Lauscher, Anne  and
      Glava{\v{s}}, Goran",
    booktitle = "Proceedings of the Eighth Joint Conference on Lexical and Computational Semantics (*{SEM} 2019)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/S19-1010",
    doi = "10.18653/v1/S19-1010",
    pages = "85--91",
    abstract = "Word embeddings have recently been shown to reflect many of the pronounced societal biases (e.g., gender bias or racial bias). Existing studies are, however, limited in scope and do not investigate the consistency of biases across relevant dimensions like embedding models, types of texts, and different languages. In this work, we present a systematic study of biases encoded in distributional word vector spaces: we analyze how consistent the bias effects are across languages, corpora, and embedding models. Furthermore, we analyze the cross-lingual biases encoded in bilingual embedding spaces, indicative of the effects of bias transfer encompassed in cross-lingual transfer of NLP models. Our study yields some unexpected findings, e.g., that biases can be emphasized or downplayed by different embedding models or that user-generated content may be less biased than encyclopedic text. We hope our work catalyzes bias research in NLP and informs the development of bias reduction techniques.",
}

@inproceedings{tang2014learning,
    title = "Learning Sentiment-Specific Word Embedding for Twitter Sentiment Classification",
    author = "Tang, Duyu  and
      Wei, Furu  and
      Yang, Nan  and
      Zhou, Ming  and
      Liu, Ting  and
      Qin, Bing",
    booktitle = "Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jun,
    year = "2014",
    address = "Baltimore, Maryland",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P14-1146",
    doi = "10.3115/v1/P14-1146",
    pages = "1555--1565",
}


@inproceedings{xing2015normalized,
    title = "Normalized Word Embedding and Orthogonal Transform for Bilingual Word Translation",
    author = "Xing, Chao  and
      Wang, Dong  and
      Liu, Chao  and
      Lin, Yiye",
    booktitle = "Proceedings of the 2015 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = may # "{--}" # jun,
    year = "2015",
    address = "Denver, Colorado",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N15-1104",
    doi = "10.3115/v1/N15-1104",
    pages = "1006--1011",
}


@inproceedings{tosik2015word,
    title = "Word Embeddings vs Word Types for Sequence Labeling: the Curious Case of {CV} Parsing",
    author = "Tosik, Melanie  and
      Lygteskov Hansen, Carsten  and
      Goossen, Gerard  and
      Rotaru, Mihai",
    booktitle = "Proceedings of the 1st Workshop on Vector Space Modeling for Natural Language Processing",
    month = jun,
    year = "2015",
    address = "Denver, Colorado",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W15-1517",
    doi = "10.3115/v1/W15-1517",
    pages = "123--128",
}

@INPROCEEDINGS{nasser2018convolutional,
  author={S. {Nasser} and C. {Sreejith} and M. {Irshad}},
  booktitle={2018 International Conference on Emerging Trends and Innovations In Engineering And Technological Research (ICETIETR)}, 
  title={Convolutional Neural Network with Word Embedding Based Approach for Resume Classification}, 
  year={2018},
  volume={},
  number={},
  pages={1-6},
  abstract={Document Classification is a very prominent area, it is applicable for adiversity of novel applications. ln this study, we focussed on classifying resumes to different classes. The proposed approach is for classifying resumes using Convolutional Neural Network with Glove-Word Embedding. We have segmented resumes into various levels and a hierarchy of classification levels is created. For each level, the CNN with word embedding model is used for classification. The output of each classifier is later combined to define the overall hierarchy of the resume category. Results are evaluated using the performance measures such as precision, recall, and f-score. The results obtained are promising and the proposed system is helpful in the recruitment and selection process of candidates.},
  keywords={convolution;feedforward neural nets;pattern classification;recruitment;word processing;Glove-Word Embedding;word embedding model;resume category;convolutional neural network;resume classification;document classification;recruitment;Resumes;Feature extraction;Training;Convolutional neural networks;Task analysis;Text categorization;Classification algorithms;CNN;Deep Learning;Glove;Neural Network;Word Embedding},
  doi={10.1109/ICETIETR.2018.8529097},
  ISSN={},
  month={July},
}

@article{lucy_linguistic_1997,
    author = {Lucy, John A.},
    title = {Linguistic Relativity},
    journal = {Annual Review of Anthropology},
    volume = {26},
    number = {1},
    pages = {291-312},
    year = {1997},
    doi = {10.1146/annurev.anthro.26.1.291},
    URL = { https://doi.org/10.1146/annurev.anthro.26.1.291 },
    eprint = { https://doi.org/10.1146/annurev.anthro.26.1.291 },
    abstract = { The linguistic relativity hypothesis, the proposal that the particular language we speak influences the way we think about reality, forms one part of the broader question of how language influences thought. Despite long-standing historical interest in the hypothesis, there is relatively little empirical research directly addressing it. Existing empirical approaches are classified into three types. 1. Structure-centered approaches begin with language differences and ask about their implications for thought. 2. Domain-centered approaches begin with experienced reality and ask how different languages encode it. 3. Behavior-centered approaches begin with some practical concern and seek an explanation in language. These approaches are compared, and recent methodological improvements highlighted. Despite empirical advances, a theoretical account needs to articulate exactly how languages interpret experiences and how those interpretations influence thought. This will entail integrating theory and data concerning both the general relation of language and thought and the shaping influence of specific discursive structures and practices. }
}

@inproceedings{collier_wikipedia_gender_gap_2012,
author = {Collier, Benjamin and Bear, Julia},
title = {Conflict, Criticism, or Confidence: An Empirical Examination of the Gender Gap in Wikipedia Contributions},
year = {2012},
isbn = {9781450310864},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2145204.2145265},
doi = {10.1145/2145204.2145265},
booktitle = {Proceedings of the ACM 2012 Conference on Computer Supported Cooperative Work},
pages = {383–392},
numpages = {10},
keywords = {wikipedia, confidence, survey, criticism, gender, conflict},
location = {Seattle, Washington, USA},
series = {CSCW ’12}
}
