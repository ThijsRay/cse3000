\documentclass[english, a4paper, 11pt]{article}
\usepackage[T1]{fontenc}
\usepackage[latin9]{inputenc}
\usepackage{geometry}
\usepackage{csquotes}
\usepackage[style=ieee,sortcites=true,sorting=nyt]{biblatex}
\addbibresource{references.bib}
\geometry{verbose,tmargin=3cm,bmargin=3cm,lmargin=3cm,rmargin=3cm}

\makeatletter
\usepackage{url}

\makeatother

\usepackage{babel}


\title{Research Plan Week 1--2}
\author{Thijs Raymakers}
\date{2020-04-20}

\newcommand{\namelistlabel}[1]{\mbox{#1}\hfil}
\newenvironment{namelist}[1]{%1
\begin{list}{}
    {
        \let\makelabel\namelistlabel
        \settowidth{\labelwidth}{#1}
        \setlength{\leftmargin}{1.1\labelwidth}
    }
  }{%1
\end{list}}

\begin{document}
\maketitle

\begin{namelist}{xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx}
\item[{\bf Title:}]
    Gender bias between languages
\item[{\bf Author:}]
    Thijs Raymakers (4647610)
\item[{\bf Responsible Professor:}]
    David Tax, Marco Loog
%\item[{\bf (Optionally) Other Supervisor:}]
%	Eva
%\item[{\bf (Required for final version) Examiner:}]
%	Another Professor (\emph{interested, but not involved})
\item[{\bf Peer group members:}]
    Pia Keukeleire, 
    Thomas van Tussenbroek,
    David Happel,
    Dina Chen,
    Katja Schmahl
\end{namelist}


\section*{Background of the research}
Word embeddings are being used to capture the meaning and the semantics of words as a
mathematical vector. They are being used in various applications where structural
analysis of text or language is required. However, these word embeddings encode
human biases \cite{caliskan_2017_semantics_language_corpora, 2019arXiv190509866N, 2017arXiv171108412G, 2018arXiv180309288K, 2019arXiv190303862G}. One of the biases that is often
measured is the gender bias in an embedding. This is classically demonstrated with the
use of analogies such as \textit{man is to king as woman is to queen} or \textit{man is to doctor as woman is to nurse}~\cite{2019arXiv190509866N}.
However, as described in~\cite{2019arXiv190509866N}, one should be careful when using
analogies to measure bias in word embeddings. They describe that the code to calculate
the analogies might be too constrained, since the situation \textit{A is to B as C is to D}
where \textit{B == D} could be impossible to obtain~\cite{2019arXiv190509866N}. Besides
that, it would not always be clear what a factual answer of \textit{D} would be.

This raises an interesting question on how to measure bias in word embeddings without
having the problems that were addressed in~\cite{2019arXiv190509866N}.

\section*{Research Question}
The research would focus on the following question:

\begin{quote}
    To what extend is there a difference between the gender bias of word embeddings
    trained on different languages?
\end{quote}

My hypothesis here would be that the difference in gender bias between word embeddings 
trained on languages in the same branch of language families is relatively small, while
the difference between word embeddings trained on languages in different branches of
language families is relatively large.
For example, I expect that the differences in gender bias between Dutch and English are
relatively small, since they are both Germanic languages. On the other hand, I expect the
difference between English and Chinese to be relatively large, since they are not in the
same branch of language families.

\section*{Method}
In this section you should outline how you intend to go about accomplishing the aims you have set in the previous section. 
For now, list some possible tools/software/data that may be relevant for you and that you will need to choose from in the first two weeks.


\section*{Planning of the first two weeks}
Arrange meetings with relevant people in the first two weeks (e.g.\ responsible professor, supervisor, peer students, other people in the research group, potential users of your research).
Summarize your main tasks for the first two weeks, resulting in the submission of a more detailed research proposal.

\printbibliography

\end{document}
